{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8287f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from solver import Solver\n",
    "from data_loader import get_loader\n",
    "from torch.backends import cudnn\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb742fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    cudnn.benchmark = True\n",
    "    if config.model_type not in ['U_Net','R2U_Net','AttU_Net','R2AttU_Net']:\n",
    "        print('ERROR!! model_type should be selected in U_Net/R2U_Net/AttU_Net/R2AttU_Net')\n",
    "        print('Your input for model_type was %s'%config.model_type)\n",
    "        return\n",
    "    # 将 cudnn.benchmark 设置为 True。这会启用 CuDNN 自动调谐器，以找到当前 GPU 配置的最佳算法，从而提高性能。\n",
    "    # 检查 config.model_type 是否是以下四个值之一：'U_Net'、'R2U_Net'、'AttU_Net' 或 'R2AttU_Net'。\n",
    "    # 如果 config.model_type 不是这些值之一，则函数会打印错误消息并返回。\n",
    "\n",
    "    # Create directories if not exist\n",
    "    if not os.path.exists(config.model_path):\n",
    "        os.makedirs(config.model_path)\n",
    "    if not os.path.exists(config.result_path):\n",
    "        os.makedirs(config.result_path)\n",
    "    config.result_path = os.path.join(config.result_path,config.model_type)\n",
    "    if not os.path.exists(config.result_path):\n",
    "        os.makedirs(config.result_path)\n",
    "    # 如果 config.model_path 和 config.result_path 不存在，则创建这两个目录。如果它们已经存在，则不进行任何操作。\n",
    "    # 将 config.model_type 添加到 config.result_path，并在必要时创建该目录。\n",
    "    \n",
    "    lr = random.random()*0.0005 + 0.0000005\n",
    "    augmentation_prob= random.random()*0.7\n",
    "    epoch = random.choice([100,150,200,250])\n",
    "    decay_ratio = random.random()*0.8\n",
    "    decay_epoch = int(epoch*decay_ratio)\n",
    "    #生成四个随机的超参数：\n",
    "\n",
    "    # lr：介于 5e-7 和 5e-4 之间的学习率。\n",
    "    # augmentation_prob：介于 0 和 0.7 之间的概率，决定是否在训练期间对输入图像进行数据增强。\n",
    "    # epoch：从列表 [100, 150, 200, 250] 中随机选择的训练周期数。\n",
    "    # decay_ratio：介于 0 和 0.8 之间的比率，决定学习率在训练期间衰减的程度。\n",
    "\n",
    "    config.augmentation_prob = augmentation_prob\n",
    "    config.num_epochs = epoch\n",
    "    config.lr = lr\n",
    "    config.num_epochs_decay = decay_epoch\n",
    "\n",
    "    print(config)\n",
    "    # 将这些超参数分配给 config 中相应的值。\n",
    "        \n",
    "    train_loader = get_loader(image_path=config.train_path,\n",
    "                            image_size=config.image_size,\n",
    "                            batch_size=config.batch_size,\n",
    "                            num_workers=config.num_workers,\n",
    "                            mode='train',\n",
    "                            augmentation_prob=config.augmentation_prob)\n",
    "    valid_loader = get_loader(image_path=config.valid_path,\n",
    "                            image_size=config.image_size,\n",
    "                            batch_size=config.batch_size,\n",
    "                            num_workers=config.num_workers,\n",
    "                            mode='valid',\n",
    "                            augmentation_prob=0.)\n",
    "    test_loader = get_loader(image_path=config.test_path,\n",
    "                            image_size=config.image_size,\n",
    "                            batch_size=config.batch_size,\n",
    "                            num_workers=config.num_workers,\n",
    "                            mode='test',\n",
    "                            augmentation_prob=0.)\n",
    "\n",
    "    solver = Solver(config, train_loader, valid_loader, test_loader)\n",
    "    # 调用 get_loader 三次，创建训练、验证和测试数据集的数据加载器。\n",
    "    # 函数 get_loader 返回一个 PyTorch DataLoader 对象，以批处理方式加载数据集。\n",
    "\n",
    "    \n",
    "    # Train and sample the images\n",
    "    if config.mode == 'train':\n",
    "        solver.train()\n",
    "    elif config.mode == 'test':\n",
    "        solver.test()\n",
    "    # 使用 config、train_loader、valid_loader 和 test_loader 作为参数创建 Solver 对象。\n",
    "\n",
    "    # 如果 config.mode 为 'train'，则调用 Solver 对象的 train() 方法来训练模型。\n",
    "    # 如果 config.mode 为 'test'，则调用 Solver 对象的 test() 方法来评估模型在测试数据集上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b49212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augmentation_prob=0.22469787658989807, batch_size=1, beta1=0.5, beta2=0.999, cuda_idx=1, image_size=224, img_ch=3, log_step=2, lr=8.368461284516293e-05, mode='train', model_path='./models', model_type='U_Net', num_epochs=200, num_epochs_decay=146, num_workers=8, output_ch=1, result_path='./result/U_Net', t=3, test_path='./dataset/test/', train_path='./dataset/train/', val_step=2, valid_path='./dataset/valid/')\n",
      "image count in train path :0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16352\\1751793786.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16352\\2672425875.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     33\u001b[0m                             \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                             augmentation_prob=config.augmentation_prob)\n\u001b[0m\u001b[0;32m     36\u001b[0m     valid_loader = get_loader(image_path=config.valid_path,\n\u001b[0;32m     37\u001b[0m                             \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Image_Segmentation-master\\Image_Segmentation-master\\data_loader.py\u001b[0m in \u001b[0;36mget_loader\u001b[1;34m(image_path, image_size, batch_size, num_workers, mode, augmentation_prob)\u001b[0m\n\u001b[0;32m    102\u001b[0m                                                                   \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                                                   \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \t\t\t\t\t\t\t\t  num_workers=num_workers)\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\py3.7\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# map-style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\py3.7\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m--> 108\u001b[1;33m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    \n",
    "    # model hyper-parameters\n",
    "    parser.add_argument('--image_size', type=int, default=224)\n",
    "    #--image_size：输入图像的大小（默认值：224）\n",
    "    parser.add_argument('--t', type=int, default=3, help='t for Recurrent step of R2U_Net or R2AttU_Net')\n",
    "    #--t：用于R2U-Net或R2AttU-Net架构的循环步骤数量（默认值：3）\n",
    "    \n",
    "    # training hyper-parameters\n",
    "    parser.add_argument('--img_ch', type=int, default=3)\n",
    "    #--t：用于R2U-Net或R2AttU-Net架构的循环步骤数量（默认值：3）\n",
    "    parser.add_argument('--output_ch', type=int, default=1)\n",
    "    #--output_ch：输出分割掩模中的通道数（默认值：1）\n",
    "    parser.add_argument('--num_epochs', type=int, default=100)\n",
    "        #--num_epochs：训练的总时期数量（默认值：100）\n",
    "    parser.add_argument('--num_epochs_decay', type=int, default=70)\n",
    "    #--num_epochs_decay：开始衰减学习率的时期数量（默认值：70）\n",
    "    parser.add_argument('--batch_size', type=int, default=1)\n",
    "    #--batch_size：训练的批处理大小（默认值：1）\n",
    "    parser.add_argument('--num_workers', type=int, default=8)\n",
    "    #--num_workers：用于加载数据的工作线程数量（默认值：8）\n",
    "    parser.add_argument('--lr', type=float, default=0.0002)\n",
    "    #--lr：初始学习率（默认值：0.0002）\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)        # momentum1 in Adam\n",
    "    #--beta1：Adam优化器的动量参数（默认值：0.5）\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)      # momentum2 in Adam \n",
    "    #--beta2：Adam优化器的第二动量参数（默认值：0.999）\n",
    "    parser.add_argument('--augmentation_prob', type=float, default=0.4)\n",
    "    #--augmentation_prob：对训练数据应用数据增强的概率（默认值：0.4）\n",
    "\n",
    "    parser.add_argument('--log_step', type=int, default=2)\n",
    "    #--log_step：打印训练损失的间隔（默认值：2）\n",
    "    parser.add_argument('--val_step', type=int, default=2)\n",
    "    #--val_step：训练过程中运行验证的间隔（默认值：2）\n",
    "\n",
    "    # misc\n",
    "    parser.add_argument('--mode', type=str, default='train')\n",
    "    #--mode：脚本的模式，\"train\"或\"test\"（默认值：\"train\"）\n",
    "    parser.add_argument('--model_type', type=str, default='R2AttU_Net', help='U_Net/R2U_Net/AttU_Net/R2AttU_Net')\n",
    "    #--model_type：要使用的模型体系结构类型之一，\"U_Net\"、\"R2U_Net\"、\"AttU_Net\"或\"R2AttU_Net\"（默认值：\"R2AttU_Net\"）\n",
    "    parser.add_argument('--model_path', type=str, default='./models')\n",
    "    #--model_path：保存训练模型权重的路径（默认值：\"./models\"）\n",
    "    parser.add_argument('--train_path', type=str, default='./dataset/train/')\n",
    "    #--train_path：训练数据目录的路径（默认值：\"./dataset/train/\"）\n",
    "    parser.add_argument('--valid_path', type=str, default='./dataset/valid/')\n",
    "    #--valid_path：验证数据目录的路径（默认值：\"./dataset/valid/\"）\n",
    "    parser.add_argument('--test_path', type=str, default='./dataset/test/')\n",
    "    #--test_path：测试数据目录的路径（默认值：\"./dataset/test/\"）\n",
    "    parser.add_argument('--result_path', type=str, default='./result/')\n",
    "    #--result_path：保存分割结果的路径（默认值：\"./result/\"\n",
    "\n",
    "    parser.add_argument('--cuda_idx', type=int, default=1)\n",
    "\n",
    "    config =  parser.parse_known_args()[0]\n",
    "    main(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b72474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
